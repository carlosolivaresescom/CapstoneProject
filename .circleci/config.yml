version: 2.1
orbs:
  slack: circleci/slack@4.5.3

commands:
  destroy-environment:
    description: Destroy back-end and front-end cloudformation stacks given a workflow ID.
    steps:
      - run:
          name: Destroy environments
          when: on_fail
          command: |
            echo "Destroying environments ${CIRCLE_WORKFLOW_ID:0:7}"
            aws cloudformation delete-stack --stack-name capstone-ecr-${CIRCLE_WORKFLOW_ID:0:7}
            aws cloudformation delete-stack --stack-name capstone-network-${CIRCLE_WORKFLOW_ID:0:7}

jobs:
  build:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [build]
      - run:
          name: Build
          command: |
            cd backend
            npm install
            npm run build
      - save_cache:
          paths: [build/node_modules]
          key: build

  test-backend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          key: build
      - run:
          name: Run build test
          command: |
            cd backend
            npm install
            npm run test

  deploy-ecr-infrastructure:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Deploy ecr
          command: |
            aws cloudformation deploy \
              --template-file .circleci/files/ecr.yml \
              --tags project=capstone \
              --stack-name "capstone-ecr-${CIRCLE_WORKFLOW_ID:0:7}" \
              --parameter-overrides ID="${CIRCLE_WORKFLOW_ID:0:7}" \
              --region=us-east-1

  upload-docker:
    docker:
      - image: docker:18.09-git
    steps:
      - checkout
      - run:
          name: install dependencies
          command: |
            apk add --no-cache \
            python3 \
            py3-pip \
            && pip3 install --upgrade pip \
            && pip3 install \
                awscli \
            && rm -rf /var/cache/apk/*
      - setup_remote_docker:
          docker_layer_caching: true
      - run:
          name: Build docker
          command: |
            cd backend
            docker build -t capstoneproject .
            docker images
      - run:
          name: Tag docker image
          command: |
            cd backend
            export ECRURI=$(aws cloudformation list-exports --query "Exports[?Name=='${CIRCLE_WORKFLOW_ID:0:7}-ECR-Uri'].Value" --no-paginate --output text)
            export registry=${ECRURI%/*}
            echo ${registry}
            aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin ${registry}
            echo ${ECRURI}:latest
            docker tag capstoneproject ${ECRURI}:latest
            docker images
            docker push ${ECRURI}:latest

  deploy-infrastructure:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: install tar and gzip
          command: |
            yum install -y tar gzip
      - run:
          name: Deploy server
          command: |
            aws cloudformation deploy \
              --template-file .circleci/files/server.yml \
              --tags project=capstone \
              --stack-name "capstone-server-${CIRCLE_WORKFLOW_ID:0:7}" \
              --parameter-overrides ID="${CIRCLE_WORKFLOW_ID:0:7}" \
              --region=us-east-1
      - run:
          name: Add back-end ip to ansible inventory
          command: |
            echo $(aws cloudformation list-exports --query "Exports[?Name=='${CIRCLE_WORKFLOW_ID:0:7}-PublicIp'].Value" --no-paginate --output text) >> .circleci/ansible/inventory.txt
            cat .circleci/ansible/inventory.txt
      - persist_to_workspace:
          root: ~/
          paths:
            - project/.circleci/ansible/inventory.txt
      - destroy-environment

  configure-infrastructure:
    docker:
      - image: python:3.7-alpine3.11
    steps:
      - checkout
      - add_ssh_keys:
          fingerprints:
            ["72:72:47:81:43:60:4c:c2:67:48:78:00:ef:84:b4:31:4d:19:8a:ae"]
      - attach_workspace:
          at: ~/
      - run:
          name: Install dependencies
          command: |
            apk add --update ansible
            apk add --no-cache tar
            apk add --no-cache \
            python3 \
            py3-pip \
            && pip3 install --upgrade pip \
            && pip3 install \
                awscli \
            && rm -rf /var/cache/apk/*
      - run:
          name: Configure server
          command: |
            cd .circleci/ansible
            cat inventory.txt
            ansible-playbook -i inventory.txt configure-server.yml
            exit 1
          environment:
            ANSIBLE_HOST_KEY_CHECKING: false
            AWS_ACCESS_KEY_ID: $AWS_ACCESS_KEY_ID
            AWS_DEFAULT_REGION: $AWS_DEFAULT_REGION
            AWS_SECRET_ACCESS_KEY: $AWS_SECRET_ACCESS_KEY
      - destroy-environment

  create-cluster:
    docker:
      - image: alpine/k8s:1.15.12
    steps:
      - checkout
      - run:
          name: Store old cluster in file
          command: |
            echo $(aws eks list-clusters | python3 -c "import sys, json; print(json.load(sys.stdin)['clusters'][0])") > clusterName.txt
            cat clusterName.txt
      - run:
          name: Create cluster
          command: |
            export clustername="capstone-${CIRCLE_WORKFLOW_ID:0:7}"
            echo ${clustername}
            sed -e "s/clustername/$clustername/g" .circleci/files/create.yml | eksctl create cluster -f -
            #eksctl create cluster -f .circleci/files/create.yml
      - run:
          name: Get pods
          command: |
            kubectl get pods
      - setup_remote_docker:
          docker_layer_caching: true
      - run:
          name: Run kubectl
          command: |
            kubectl apply -f .circleci/files/deployment.yml
            kubectl apply -f .circleci/files/ecrserver.yml
            kubectl get all
      - run:
          name: Add ip to file
          command: |
            echo "$(kubectl get services kubeapp-ecr-nodeport-service)" > ip.txt
            cat ip.txt
      - persist_to_workspace:
          root: /tmp
          paths:
            - ip.txt
            - clusterName.txt
      - destroy-environment

  test:
    machine: true
    steps:
      - checkout
      - run:
          name: build images
          command: |
            cd backend2
            docker build -t capstoneproject .
            docker images
      - run:
          name: push to docker hub
          command: |
            docker login -u ${DOCKER_USER} -p ${DOCKER_PASSWORD}
            docker tag capstoneproject ${DOCKER_USER}/capstoneproject
            docker push ${DOCKER_USER}/capstoneproject

workflows:
  default:
    jobs:
      #- deploy-ecr-infrastructure:
      #    filters:
      #      branches:
      #        only: main
      #- upload-docker:
      #    filters:
      #      branches:
      #        only: main
      #    requires: [deploy-ecr-infrastructure]
      #- deploy-infrastructure:
      #    filters:
      #      branches:
      #        only: main
      #requires: [upload-docker]
      #- configure-infrastructure:
      #    filters:
      #      branches:
      #        only: main
      #    requires: [deploy-infrastructure]

      - test:
          filters:
            branches:
              only: main
      - create-cluster:
          filters:
            branches:
              only: main
          requires: [test]
